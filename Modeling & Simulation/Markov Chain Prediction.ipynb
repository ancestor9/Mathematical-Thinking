{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP+WxAzDr27mQDdW56DdLiJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import random\n","\n","# 1. 상태 공간 정의\n","states = [\"Sunny\", \"Cloudy\", \"Rainy\"]\n","\n","# 2. 전이 행렬 (Transition Matrix) 정의\n","# 행(Row): 현재 상태 / 열(Column): 다음 상태\n","# 순서: [Sunny, Cloudy, Rainy]\n","# 예: transition_matrix[0][1]은 Sunny -> Cloudy 확률 (0.3)\n","transition_matrix = [\n","    [0.6, 0.3, 0.1],  # Sunny일 때\n","    [0.3, 0.4, 0.3],  # Cloudy일 때\n","    [0.2, 0.3, 0.5]   # Rainy일 때\n","]\n","\n","# 확률 행렬 검증 (각 행의 합은 1이어야 함)\n","for i, row in enumerate(transition_matrix):\n","    assert sum(row) == 1.0, f\"Row {i} probabilities must sum to 1\"\n","\n","def simulate_weather(days, start_state=\"Sunny\"):\n","    \"\"\"\n","    주어진 일수(days) 동안 날씨를 시뮬레이션하는 함수\n","    \"\"\"\n","    current_state = start_state\n","    weather_sequence = [current_state]\n","\n","    print(f\"--- 시뮬레이션 시작 (초기 상태: {start_state}) ---\")\n","\n","    for i in range(days):\n","        # 현재 상태의 인덱스 찾기\n","        curr_idx = states.index(current_state)\n","\n","        # 현재 상태에 따른 다음 상태의 확률 분포 가져오기\n","        probs = transition_matrix[curr_idx]\n","\n","        # 확률에 따라 다음 상태 결정 (np.random.choice 사용)\n","        next_state = np.random.choice(states, p=probs)\n","\n","        weather_sequence.append(next_state)\n","        current_state = next_state\n","\n","    return weather_sequence\n","\n","# --- 실행 ---\n","# 7일간의 날씨 변화 시뮬레이션\n","simulation_days = 7\n","result = simulate_weather(simulation_days, start_state=\"Sunny\")\n","\n","print(\"\\n[결과: 7일간의 날씨 변화]\")\n","print(\" -> \".join(result))\n","\n","# 상태별 발생 횟수 통계\n","from collections import Counter\n","counts = Counter(result)\n","print(f\"\\n[통계] 맑음: {counts['Sunny']}회, 흐림: {counts['Cloudy']}회, 비: {counts['Rainy']}회\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xsRsqbkOpy-6","executionInfo":{"status":"ok","timestamp":1765208966043,"user_tz":-540,"elapsed":44,"user":{"displayName":"sanggoo cho","userId":"05013997244878666178"}},"outputId":"173b4423-7f0b-43eb-a9ec-18c18559f984"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--- 시뮬레이션 시작 (초기 상태: Sunny) ---\n","\n","[결과: 7일간의 날씨 변화]\n","Sunny -> Cloudy -> Cloudy -> Cloudy -> Cloudy -> Cloudy -> Cloudy -> Sunny\n","\n","[통계] 맑음: 2회, 흐림: 6회, 비: 0회\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Et_9Vca_o254","executionInfo":{"status":"ok","timestamp":1765208726026,"user_tz":-540,"elapsed":19,"user":{"displayName":"sanggoo cho","userId":"05013997244878666178"}},"outputId":"fcf73508-5b9f-43f5-f421-273976a9e301"},"outputs":[{"output_type":"stream","name":"stdout","text":["학습 완료! 총 25개의 단어 관계를 학습했습니다.\n","\n","[생성된 문장들]\n","1. 기사는 용감했다. 용은 불을 뿜었다.\n","2. 용은 불을 뿜었다. 불을 피한\n","3. 불을 피한 기사는 검을 들었다. 기사는\n"]}],"source":["import random\n","\n","class MarkovTextGenerator:\n","    def __init__(self):\n","        # 단어의 연결 관계를 저장할 딕셔너리\n","        # 예: {'나는': ['학교에', '집에', '밥을'], '학교에': ['갑니다', '있습니다']}\n","        self.chain = {}\n","\n","    def train(self, text):\n","        \"\"\"\n","        텍스트 데이터를 읽어 단어 간의 전이 확률(연결 관계)을 학습합니다.\n","        \"\"\"\n","        # 1. 텍스트를 공백 기준으로 단어 분리\n","        words = text.split()\n","\n","        # 2. 현재 단어와 다음 단어를 짝지어 딕셔너리에 저장\n","        for i in range(len(words) - 1):\n","            current_word = words[i]\n","            next_word = words[i + 1]\n","\n","            if current_word not in self.chain:\n","                self.chain[current_word] = []\n","\n","            self.chain[current_word].append(next_word)\n","\n","        print(f\"학습 완료! 총 {len(self.chain)}개의 단어 관계를 학습했습니다.\")\n","\n","    def generate(self, start_word, length=10):\n","        \"\"\"\n","        시작 단어 주어지면 마르코프 체인을 따라 문장을 생성합니다.\n","        \"\"\"\n","        if start_word not in self.chain:\n","            return \"오류: 학습된 데이터에 없는 시작 단어입니다.\"\n","\n","        # 시작 단어로 문장 시작\n","        current_word = start_word\n","        sentence = [current_word]\n","\n","        for _ in range(length - 1):\n","            # 현재 단어 뒤에 올 수 있는 단어 목록을 가져옴\n","            next_words = self.chain.get(current_word)\n","\n","            # 더 이상 이어질 단어가 없으면 중단\n","            if not next_words:\n","                break\n","\n","            # 목록 중 하나를 랜덤하게 선택 (확률적 선택)\n","            next_word = random.choice(next_words)\n","\n","            sentence.append(next_word)\n","            current_word = next_word\n","\n","        return \" \".join(sentence)\n","\n","# --- 실행 예시 ---\n","\n","# 1. 학습할 텍스트 데이터 (반복되는 패턴이 있을수록 재미있는 결과가 나옵니다)\n","training_data = \"\"\"\n","기사는 검을 들었다. 기사는 용을 향해 달렸다.\n","용은 불을 뿜었다. 불을 피한 기사는 용을 공격했다.\n","용은 하늘로 날아올랐다. 기사는 하늘을 쳐다보았다.\n","공주는 기사를 걱정했다. 기사는 공주를 위해 싸웠다.\n","검을 든 기사는 용감했다. 용은 무서운 소리를 냈다.\n","\"\"\"\n","\n","# 2. 봇 생성 및 학습\n","bot = MarkovTextGenerator()\n","bot.train(training_data)\n","\n","# 3. 문장 생성 테스트\n","print(\"\\n[생성된 문장들]\")\n","print(\"1.\", bot.generate(\"기사는\", length=5))\n","print(\"2.\", bot.generate(\"용은\", length=5))\n","print(\"3.\", bot.generate(\"불을\", length=6))"]},{"cell_type":"code","source":["!pip install markovify\n","import requests\n","import markovify\n","\n","def load_gutenberg_text(url):\n","    \"\"\"\n","    URL에서 텍스트를 다운로드하고, 구텐베르크의 헤더/푸터(라이선스 고지 등)를 제거합니다.\n","    \"\"\"\n","    print(f\"다운로드 중... {url}\")\n","    response = requests.get(url)\n","    response.encoding = 'utf-8' # 인코딩 설정\n","    text = response.text\n","\n","    # 구텐베르크 텍스트에는 소설 내용 앞뒤로 긴 라이선스 설명이 붙어 있습니다.\n","    # 이를 제거하고 순수 본문만 추출하는 과정입니다.\n","\n","    # 본문 시작과 끝을 알리는 마커 (책마다 조금씩 다를 수 있으나 보통 이렇습니다)\n","    start_marker = \"*** START OF THE PROJECT GUTENBERG EBOOK\"\n","    end_marker = \"*** END OF THE PROJECT GUTENBERG EBOOK\"\n","\n","    start_idx = text.find(start_marker)\n","    end_idx = text.find(end_marker)\n","\n","    # 마커를 찾았다면 그 사이의 텍스트만, 못 찾았다면 전체 텍스트 반환\n","    if start_idx != -1 and end_idx != -1:\n","        # start_marker 줄바꿈 이후부터 end_marker 전까지\n","        real_text = text[start_idx:end_idx]\n","        # 앞부분의 'START...' 문구 제거를 위해 조금 더 다듬기\n","        real_text = real_text.split('\\n', 1)[-1]\n","        return real_text\n","\n","    return text\n","\n","# --- 메인 실행부 ---\n","\n","# 1. 데이터 가져오기 (이상한 나라의 앨리스 - Lewis Carroll)\n","url = \"https://www.gutenberg.org/files/11/11-0.txt\"\n","text_data = load_gutenberg_text(url)\n","\n","print(f\"\\n[데이터 로드 완료] 텍스트 길이: {len(text_data)}자\")\n","\n","# 2. Markovify 모델 빌드 (State Size=2)\n","# state_size=2는 '현재 단어' 1개가 아니라 '앞의 두 단어'를 보고 다음을 예측한다는 뜻입니다.\n","# 문맥이 훨씬 자연스러워집니다.\n","text_model = markovify.Text(text_data, state_size=2)\n","\n","print(\"모델 학습 완료! 문장을 생성합니다...\\n\")\n","print(\"-\" * 50)\n","\n","# 3. 문장 생성 (5개 시도)\n","for i in range(5):\n","    # make_sentence: 문장의 시작과 끝(마침표 등)을 고려해 자연스러운 문장을 만듭니다.\n","    sentence = text_model.make_sentence(tries=100)\n","\n","    if sentence:\n","        print(f\"{i+1}. {sentence}\")\n","    else:\n","        print(f\"{i+1}. (문장 생성 실패 - 조건에 맞는 문장을 못 찾음)\")\n","\n","print(\"-\" * 50)\n","\n","# 4. 짧은 문장 생성 (옵션)\n","print(\"\\n[짧은 문장 생성 예시 (140자 이내)]\")\n","print(text_model.make_short_sentence(140))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T7oGsqC7o39l","executionInfo":{"status":"ok","timestamp":1765208909422,"user_tz":-540,"elapsed":6522,"user":{"displayName":"sanggoo cho","userId":"05013997244878666178"}},"outputId":"efe7d0ef-b349-43e0-9a5a-3365fc32c1b6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting markovify\n","  Downloading markovify-0.9.4-py3-none-any.whl.metadata (23 kB)\n","Collecting unidecode (from markovify)\n","  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n","Downloading markovify-0.9.4-py3-none-any.whl (19 kB)\n","Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: unidecode, markovify\n","Successfully installed markovify-0.9.4 unidecode-1.4.0\n","다운로드 중... https://www.gutenberg.org/files/11/11-0.txt\n","\n","[데이터 로드 완료] 텍스트 길이: 144602자\n","모델 학습 완료! 문장을 생성합니다...\n","\n","--------------------------------------------------\n","1. But there seemed to be nothing but the Rabbit came up to her that she might as well wait, as she listened, or seemed to listen, the whole pack rose up into hers—she could hear the very tones of her voice, and see what was going to give the hedgehog a blow with its mouth open, gazing up into the sky.\n","2. The poor little thing sat down and looked along the passage into the garden with one elbow against the roof of the hall: in fact she was now the right size, that it was sneezing and howling alternately without a moment’s pause.\n","3. Luckily for Alice, the little glass table.\n","4. And here poor Alice began telling them her adventures from the trees as well wait, as she could for sneezing.\n","5. Let me think: was I the same age as herself, to see that queer little toss of her hedgehog.\n","--------------------------------------------------\n","\n","[짧은 문장 생성 예시 (140자 이내)]\n","How funny it’ll seem to encourage the witness at all: he kept shifting from one minute to another!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wWYJ8ADupdxz"},"execution_count":null,"outputs":[]}]}